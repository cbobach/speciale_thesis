\documentclass[twoside,11pt,openright]{report}
%
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{appendix}
\usepackage{a4}
\usepackage{caption}
\usepackage{cite}
\usepackage{color}
\usepackage{datetime}
\usepackage{epsfig}
\usepackage{epstopdf} 
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{latexsym}
\usepackage{lmodern}
\usepackage{multirow}
\usepackage{pstricks}
\usepackage{subcaption}
\usepackage{verbatim}
%
\usepackage[english]{babel}
\usepackage[labeled]{multibib}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
%
\graphicspath{ {figurs/} }
% Usage: \todo{Document the TODO command.}
% Comment out second line to disable.
\newcommand{\todo}[1]{}
\renewcommand{\todo}[1]{{\color{red} TODO: {#1}} \\}
\renewcommand*\ttdefault{txtt}
%
\DeclareCaptionFormat{myformat}{#1#2#3\hrulefill}
\captionsetup[figure]{format=myformat}
\DeclareCaptionFormat{myformat1}{#1#2#3}
\captionsetup[subfigure]{format=myformat1}
\captionsetup[table]{format=myformat}
\captionsetup[subtable]{format=myformat1}
%
\newtheorem{theorem}{Theorem}
%
\newcommand{\FY}{\textit{Fisher-Yates} }
\newcommand{\CS}{\textit{Conditional-swap} }
\newcommand{\DUPLO}{\textit{DUPLO} }
%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagestyle{empty} 
\pagenumbering{roman} 
\vspace*{\fill}\noindent{\rule{\linewidth}{1mm}\\[4ex]
{\Huge\sf Secure Distributed Poker using MPC}\\[2ex]
{\huge\sf Christian Bobach, 20104256}\\[2ex]
\noindent\rule{\linewidth}{1mm}\\[4ex]
\noindent{\Large\sf Master's Thesis, Computer Science\\[1ex] 
          \monthname\ \the\year  \\[1ex] 
          Advisor: Claudio Orlandi\\[1ex]
          Project Advisor: Roberto Trifiletti\\[15ex]\\[\fill]}}
\epsfig{file=logo.eps}\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagestyle{plain}

%%%%%%%%%%%%%%%%%%%%%%%%% ABSTRACT %%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
\todo{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%% RESUME %%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Resum\'e}
\addcontentsline{toc}{chapter}{Resum\'e}
\todo{Resume}

%%%%%%%%%%%%%%%%%%%%% ACKNOWLEDGMENTS %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Acknowledgments}
\addcontentsline{toc}{chapter}{Acknowledgments}
During the work of my thesis I have had the help of some great people. Both when it comes to the problem of finding the right solutions, but also when looking at the nifty little details. I would like to thank Kristoffer Arnsfelt, who has been a great help in the beginning of the process, when I was trying to find the best shuffle solution to use. He came up with the idea to look into sorting networks, because he was concerned with the security of the \FY algorithm. Ni Ni Trieu has been a great help with learning to understanding the $Frigate$ compiler. She has all ways been ready to answer my stupid questions fast, in a short precise way. I would like to thank Claudio Orlandi, for the well guided hand he has been giving me through the thesis. He has always been open hearted, and said what was on his mind regarding the project. Roberto Trifiletti should have my biggest thank as he proposed this exciting project to me many month ago, even before the \DUPLO was a reality. He has supported me with all his knowledge during the project, from the early beginning to the bitter end. He has been there every time I needed someone to discuss a problem or solution with. Lastly but not leas I need to thank my wife for holding up with me, when I when on one of my coding sprees, and for her details for commas.\\
Thank you everyone.

\vspace{2ex}
\begin{flushright}
  \emph{Christian Bobach,}\\
  \emph{Aarhus, \today.}
\end{flushright}

\tableofcontents
\pagenumbering{arabic}
\setcounter{secnumdepth}{2}

%%%%%%%%%%%%%%%%%%%%%%% INTRODUCTION %%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
\label{ch:intro}
In this thesis I have made a practical study of the application for a Multi Party Computation(MPC) protocol. To show what can be done by a MPC protocol and how it can be used, a poker game has been developed as a proof of concept.

It is easy to think of how one could be cheated when playing an online game of poker. It is hard for me as a player to know if the dealer and one of the other players has an arrangement such that the dealer always deals better cards to that player such this player wins in the long run. The idea by using a MPC protocol here is to guarantee that the cards are dealt fairly. Such that the player of online poker can trust the protocol and know that the cards are guaranteed to be dealt fairly.

To ensure that the card are dealt fairly I will use a MPC protocol to take care of the shuffling of the cards. In this study I will use a two party computation(2PC) protocol called \DUPLO which will be introduced in chapter \ref{ch:duplo}. In this thesis a two party heads up poker game will be studied. The study is a showcase of the possibilities of MPC protocols and what can be achieved by them. It should be possible to easy extend the work done in this thesis to work in cases with more that only two parties using a another MPC protocol designed for that purpose. It should also be equally easy to extend the game to work with more players.

The hope is to show that a MPC protocol can be used to guarantee that the cards are deal fairly without any big cost in terms of time delay for the players.

\bigskip

For the implementation of the poker game I have studied various fields both in computer science and other fields. I have read up on different types of poker games to figure out which one was best suited for a two party setting. I have studied the underlying MPC protocol to understand how it works and to ensure that it for fills the right properties needed for an application as a poker game. I have studied different permutation algorithms and implemented them to compare them and see what effects they have on the underlying protocol.

\section{Chapter Overviews}

I will now give a short introduction to each chapter such that you as a reader know what to expect. 

\paragraph{Chapter \ref{ch:duplo}:}
In chapter \ref{ch:duplo} I cover the basics of \DUPLO. The idea and their claims. I introduce why this protocol and framework was chosen. I argue for the security of the protocol and why it covers the case of implementing poker. Lastly I explain how the circuit compiler used in this project which shipped with the \DUPLO project works.
\todo{Introduce chapter duplo}

\paragraph{Chapter \ref{ch:shuffle}:}
In chapter \ref{ch:shuffle} on shuffle algorithms I introduce the different algorithms studied during the project. I argue for the ideas behind the algorithm and why they work in the application of a poker game. I explain how the implementation of the algorithms was done. I introduce some optimizations to the algorithm such that their size in terms of gates are reduced. At last the algorithms are compared such that the most efficient one can be chosen.

\paragraph{Chapter \ref{ch:implementation}:}
In chapter \ref{ch:implementation} I describe how the poker game was implemented and how I used the \DUPLO framework. I argue for the setting chosen to implement. I discuss some of the choices done when doing the implementation which resulted in reduced communication between the parties. Lastly I discuss the benchmarking of the implementation. The benchmarking was done on different parameters, the amount of simultaneous shuffles, the effect of network latency and the effect of bandwidth. 

\paragraph{Chapter \ref{ch:conclution}:}
\todo{introduce chapter on conclusion and proposals of further studies}


\todo{Lim til f'rste kapitel}

%%%%%%%%%%%%%%%%%%%%%%%%%%% DUPLO %%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{DUPLO}
\label{ch:duplo}

In this chapter I will describe the \DUPLO framework introduced in \cite{duplo} and why this was chosen, to handle the communication and security of the poker game. I will shortly introduce the concepts of $2PC$ and $garbled~circuits$. I will explain how the structure of the \DUPLO protocol works, and give an introduction to what the different framework calls do. I will go over the security details of the protocol, to illustrate how this is guaranteed. Lastly, I will introduce the $Frigate$ compiler which ships with the \DUPLO framework to generate circuits for evaluation.

\bigskip

As it can be read in \cite{duplo}, the \DUPLO framework is among the latest papers, where the efficiency of a two party computation(2PC) protocol, using garbled circuit, in a malicious setting is studied. In the \DUPLO paper they claimed to perform better then any existing protocol. Their idea comes from the fact, that the two extreme variants of cut and chose protocols, when it is measured relative to circuit size. While they do perform well in one end of the spectrum, they do bad in the other. In the paper they propose a new approach to do cut and chose. The idea is to cut and choose sub-components of the circuit, and get an optimum somewhere in between the two extremes. The earlier protocols do cut and choose of either complete circuits or gate level. Their aim is to show, that the gate level cut and chose adds an overhead to the protocol, when the small components are soldered together again to constructing the garbled circuits for evaluation. At the same time, they try to show that when the number of sub-components goes up, there is a performance gain, when compared to cut and choose of complete garbled circuits.

As seen in section 7 on performance in \cite{duplo}, it is clear that the experiments done yields an optimal cut and chose strategy. This strategy differs from the earlier known possibilities. We see that the gain in terms of running time increases as the size of the circuit get bigger, which shows that the \DUPLO protocol scales significantly better then those it is compared to.

\bigskip

Based on these observations and the fact that it is developed at Aarhus University, such that the people with knowledge of the protocol is close by, is the main factors for choosing to use \DUPLO. The fact that \DUPLO also supports the possibility of single and distinct wire opening was important when making the decision. Exactly, the opportunity to be able to do unique wire opening, is needed to handle unique opening of cards to one player, without the other player learning anything about the card.

\bigskip

Before continuing on the introduction of the \DUPLO framework, I will explain the main ideas behind $2PC$ and $garbled~circuits$ in the next two small sections.

\bigskip

\paragraph{2PC:}
$2PC$ is a special case of $MPC$. I have used \cite{estpp} as a reference, but many others do exist. In $2PC$ only two parties $P_1$ and $P_2$ participate in the distributed evaluation of the functionality $f: \{0,1\}^* \times \{0,1\}^* \to \{0,1\}^*$. The goal in a $2PC$ protocol is to allow for evaluation of $f(x_1,x_2)=(y_1,y_2)$ between, $P_1$ with input $x_1$ and output $y_1$, and $P_2$ with input $x_2$ and output $y_2$, securely. When talking about securely evaluation, we mean the evaluation is to guarantee $privacy$ and $correctness$. $Privacy$ is to guarantee that no more than the output is learned from the computation. $Correctness$ is the ability to guarantees that the correct outputs is generated. When discussing $MPC$ we have to take $independence~of~input$, $guaranteed~output~delivery$ and $fairness$ into account. If we let $m$ denote the number of parties in a $MPC$ protocol, and let $t$ denote the threshold for the number of corrupted parties. Then in the $2PC$ case $m=2$ and $t=1$, since each party $P_i$, where $i\in\{1,2\}$, trust it self. In a $MPC$ setting $guaranteed~output~delivery$ and $fairness$ can be achieved for any protocol with a broadcast channel, with $t<\frac{m}{2}$. This implies that non of these can be achieved in a $2PC$ setting, like the one used by \DUPLO, because $1\not<\frac{2}{2}=1$. It is another case for $privacy$, $correctness$ and $independence~of~input$ which can be achieved in a $2PC$ setting. This can be done when the parties are given access to a broadcast channel, and when we assume the existence of enhanced trapdoor permutations. It is important to remember that these properties, only holds for the computational setting of adversary powers.

This ensures, that the setting studied in the \DUPLO paper can get $privacy$, $correctness$ and $independence~of~inputs$ from a $2PC$ protocol.

\paragraph{Garbled circuits:} 
The \DUPLO protocol uses what is known as encrypted circuits, or $garbled~circuits$. Once again I use \cite{estpp} as the reference. $Garbled~circuits$ is a construction where the functionality $f$, is represented as a boolean circuit $\mathcal{C}$. The garbling of $\mathcal{C}$ gives the circuit the desired abilities as argued in the section on $2PC$. We let $g:\{0,1\}\times \{0,1\} \to \{0,1\}$ denote a gate in $\mathcal{C}$. When garbling $\mathcal{C}$ it follows the garbling of all gates. Let the input wires of $g$ be labeled $w_1$ and $w_2$, and the output wire $w_3$. Let $k^0_i$ and $k^1_i$ be keys generated for each wire in $g$, where $i=1,\dots,3$, such that two keys are generated for each wire $w_i$. The idea is to be able to learn $k^{g(\alpha,\beta)}_3$ from $k^\alpha_1$ and $k^\beta_2$ without revealing any of $k^{g(1-\alpha,\beta)}_3$, $k^{g(\alpha,1-\beta)}_3$ or $k^{g(1-\alpha,1-\beta)}_3$. Let $g$ be defined by these values:

\begin{center}
    $c_{0,0} = Enc_{k^0_1}(Enc_{k^0_2}(k^{g(0,0)}_3))$    \\
    $c_{0,1} = Enc_{k^0_1}(Enc_{k^1_2}(k^{g(0,1)}_3))$    \\
    $c_{1,0} = Enc_{k^1_1}(Enc_{k^0_2}(k^{g(1,0)}_3))$    \\
    $c_{1,1} = Enc_{k^1_1}(Enc_{k^1_2}(k^{g(1,1)}_3))$    \\
\end{center}

Where $Enc$ is a private-key encryption scheme that has indistinguishable encryption under chosen plain-text attacks. $g$ is then represented by a random permutation of the values $c_{0,0}$, $c_{0,1}$, $c_{1,0}$ and $c_{1,1}$. Remember that the existence of a enhanced trapdoor permutation was a required assumption to get $privacy$, $correctness$ and $independence~of~input$, in a $2PC$ setting.

The correct $k^{g(\alpha,\beta)}_3$ can then be generated by computing $Dec_{k^\alpha_1}(Dec_{k^\beta_2}(c_{i,j})$, for $i,j\in{0,1}$. Where $Dec$ denote the corresponding decryption for $Enc$, such that for some message $m=Dec_k(Enc_k(m))$. If it is the case when decrypting, that more than one value yields a non-$\perp$, the protocol aborts, else define $k^\gamma_3$ to be the only non-$\perp$ value. Because of the chosen encryption scheme $k^\gamma_3$ is the correct value with negligible probability. When this is done to generate a complete garbled circuit $\mathcal{C}$, where the description above is followed for each gate, it will results in a garbled circuit, representing $f$ that ensures $privacy$ and $correctness$ during evaluation.


%%%%%%%%%%%%%%%%%%%%% DUPLO FRAMEWORK %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The \DUPLO framework}
\label{sec:duplo_framework}
In this section I will introduce the different functions from the \DUPLO framework and what they achieve. The \DUPLO framework consist of two parties, a $Constructor$ and an $Evaluator$ with different roles during the protocol. The $Constructor$'s main purpose is to generates or construct the garbled circuits and send to them to the $Evaluator$. The $Evaluator$ then verifies a number of these circuits, if this verification passes, the $Evaluator$ trust that the remaining circuits are valid, and these are used during evaluation. If the $Evaluator$ cannot verify the chosen circuits it aborts the protocol. The $Evaluator$ main purpose is to evaluate these circuits.

The overall construction of the \DUPLO framework consists of different functions. These functions guarantees the right communication is sent between the two parties. Because of the construction of the functions it is necessary to call them in a predetermined order, this is to ensure that the correct information is at the parties at the time when needed. When a framework defines a set of functions to be called in a given order, one function could have been used to handle the same functionality. In \DUPLO the have chosen to split it in to different functions such that local computations can be done in between these framework calls. This allows for a more modular approach when sing the framework.

\bigskip

When we interact with the framework, and run the protocol, we need to create a $Constructor$ and an $Evaluator$. When these are created they read the circuit file, specifying the functionality desired to be computed during the protocol. In our case this will be the shuffle algorithm which will be introduced in chapter \ref{ch:shuffle}.

Once the $Constructor$ and $Evaluator$ are created they run the framework function calls in parallel. If they get out of sync the protocol will abort. First the two parties call the framework function \verb|Connect|. This sets up a connection between the two parties. In this case it is the $Constructor$ hosting the service, and the $Evaluator$ connects to this. When the connection has been established, they each make a call to the \verb|Setup| function. This call initializes the commitment protocol, which will be used between the parties during the protocol. The next specified by the framework is the call to \verb|PreprocessComponetType|. This call takes $n$ and $f$ as inputs, where $n$ is the amount of garbled circuit to produce, and $f$ is the functionality that will be evaluated. This call then generates $n$ garbled representations of $f$, that can be securely evaluated.

Then a call to the \verb|PrepareComponents| function is specified. This takes $i$ as input, which is the amount of input authenticators to generate. These authenticators is used to securely transfer the input keys from the $Constructor$ to the $Evaluator$. This function also ensures that all required output authenticators are attached. The authenticators guarantees that only one valid key will flow on each wire of the garbled components. If not the $Evaluator$ will learn the $Constructors$ input.

After this, the \verb|Build| function call is done. This function takes a boolean circuit $\mathcal{C}$ as input, representing the desired functionality of the computation. The function constructs the garbled circuit, which is to be evaluated later. The \verb|Build| call ensures that the function components specified by the $\mathcal{C}$, is soldered together, such that they compute the functionality specified. This is done in such a way that the output wires from one sub-function is soldered together the right input wire of another sub-function. 

The next call is then made to \verb|Evaluate|, which takes $x_1$ and $x_2$ as input. Here $x_1$ is the input to the computation from the $Constructor$, and $x_2$ is the input from the $Evaluator$. The call then  evaluates the garbled circuit given these two inputs and yields a garbled output of the desired functionality $f(x_1,x_2)$. When the parties then hold a gabled output from the local evaluation, a call to \verb|DecodeKeys| can be made and the output of the functionality will be revealed.

\bigskip

Because the evaluation of circuits, in the \DUPLO protocol, allows for openings of distinct output wires to only one or both parties. It allows us to reveal cards to only one player and other cards to the other, without the opponent learning anything about the cards. The decision to split-up the \verb|Evaluate| and the \verb|DecodeKeys| functions will allow us to open different output wires in different rounds. This will help us to achieve a good round complexity when creating our poker implementation. This decision can also be used if the output of one circuit evaluation, will be used as input for another, such that the garbled output can be used as new inputs.


\section{Security}
\label{sec:duplo_secutity}
In this section, I will introduce the security of the protocol to show that the players playing a game of poker, using an implementation with the \DUPLO framework will have $privacy$, $correctness$ and $authenticity$. With $privacy$ is meant that the opponent can not learn more then supposed to. The play will be guaranteed $correctness$, meaning that if the garbled evaluation of the circuit is done without aborting, then it is guaranteed to give the right output. \DUPLO ensures $authenticity$, such that it is not possible for a player to do evaluation of the garbled circuit, on other input then the one provided by the parties.

\bigskip

The proof of security for the protocol is done using the Universal Composition(UC) framework, a nice introduction to the framework can be found in \cite{smcss}. The UC framework is an easy digested abstract, protocol proof technique, which allows for sequential predefined interaction between parties using actions and reactions. It has a modular approach to functionality proofs, when one functionality has been proved it can be used as a steppingstone for the next proof. In \DUPLO they use the hybrid model with ideal functionalities $\mathcal{F}_{HCOM}$ and $\mathcal{F}_{OT}$. Where the $\mathcal{F}_{HCOM}$ functionality is for the $XOR$-homomorphic commitment scheme, and $\mathcal{F}_{OT}$ for the one out of two oblivious transfer, used by the protocol. These functions are then used to prove $privacy$, $correctness$ and $authenticity$ of the protocol. 

In the section on protocol details in paper \cite{duplo}, appendix $A$, they describe and analyze the protocol. Here structuring the main protocol and going into details on how $privacy$, $correctness$ and $authenticity$ are guaranteed through the different function calls in the protocol. The proof end up being rather complex as the main structure consist of $8$ sub-functions. Where multiple of these is a combination of further sub-function. All these functions are proved to satisfy the properties mentioned above. During the analysis of these functions, they end up proving correctness of soldering and evaluation, of sub-circuits. They end up proving robustness of the key authenticator buckets, evaluation of the key authenticators, input of the $Constructor$ and $Evaluator$, evaluation of sub-circuits and the output of the $Evaluator$. This culminate in the theorem, cited here as theorem \ref{thm:2}, proving robustness of the protocol. The theorem guarantees that if the $Constructor$ is corrupt and the $Evaluator$ is honest, and the protocol does not abort, then the protocol completes holding the before mentioned properties, except with negligible probability. As known when using $MPC$ protocols, when half or more of the participating parties are corrupt, we can not guarantee termination of the protocol.

In appendix $B$ they prove the fact, that the protocol is secure against a corrupt $constructor$ or $evaluator$. Since it is a $2PC$ we may assume that one of the parties are honest, as the parties trust them self's. When proving in the UC framework, it is worth to remember that a poly-time simulator $\mathcal{S}$ should be presented. For the case of a corrupted $Constructor$, here denoted $\mathbf{C}$, and a honest $Evaluator$, denoted $\mathbf{E}$. The simulator $\mathcal{S}$ plays the role of $\mathbf{E}$ in the protocol, but is not given access to the inputs $x_{\mathbf{E}}$ of $\mathbf{E}$. Instead $\mathcal{S}$ has access to an oracle $\mathcal{O}_{x_{\mathbf{E}}}(\cdot)$ containing $x_{\mathbf{E}}$. The simulator $\mathcal{S}$ might contact the oracle $\mathcal{O_{x_{\mathbf{E}}}}$ giving input $x_{\mathbf{C}}$ and in return learn $y_{\mathbf{C}}$, as if the evaluation of the functionality was done with $x_{\mathbf{E}}$ and $x_{\mathbf{C}}$ as input.

To show that the protocol is secure in this setting, we need to show that a $\mathbf{C}$ running the protocol can not distinguish between talking to $\mathbf{E}$ or $\mathcal{S}$.

\begin{theorem}
\label{thm:2}
If constructor $\mathbf{C}$ is corrupt and evaluator $\mathbf{E}$ is honest, and the protocol does not abort, then the following holds with negligible probability. For each input gate with $id$, $\mathbf{E}$ holds $k_{id}=K^{x_{id}}_{id}$. For all input gates of $\mathbf{E}$, $x_{id}$ is the correct input of $\mathbf{E}$. For each output gate with $id'$, $\mathbf{E}$ holds $k_{id'}=k^{y_id}_{id'}$ where $y_{id}$ is the plain text value obtained by evaluating circuit $\mathcal{C}$ on $x_{id}$. The probability of the protocol aborting is independent of the inputs of $\mathbf{E}$.
\footnote{This theorem is a cited from \cite{duplo}, with small textual modifications. It can be fond as theorem 2 in appendix A.}
\end{theorem}

$\mathcal{S}$ is constructed such that it first constructs $x_\mathbf{E}=\mathbf{0}$, as the zero input vector for $\mathbf{E}$. It then inspects the commitment of the input gates of $\mathbf{C}$ and learns $k^0_{id}$ and $\Delta_{id}$, where $id$ is the gate identifier. From these $k^1_{id}$ is computed. By theorem \ref{thm:2} $k_{id}=k^{x_id}_{id}$ can be retrieved. This defines the input $x_\mathbf{C}$ for $\mathbf{C}$. $\mathcal{S}$ then calls $\mathcal{O}_{x_\mathbf{E}}(\cdot)$ with input $x_\mathbf{C}$ and learns $y_\mathbf{C}$ from $\mathcal{O}(x_\mathbf{C})$. If $y_\mathbf{C}=\perp$ then $\mathcal{S}$ aborts, else $\mathcal{S}$ sends $k_{id}$, as computed in recovery mode. This can be done since $k^0_{id}$, $k^1_{id}$ and $y_{id}$ is known to $\mathcal{S}$.

It follows from theorem \ref{thm:2} that the protocol and the simulation aborts with the same probability. When they do not abort the key returned to $\mathbf{C}$ is the same as $\mathbf{E}$ would have sent, except with negligible probability.

The same type of simulation proof is done for the case with a honest $Constructor$ and a corrupt $Evaluator$. This proof can be found in appendix B.2 in \cite{duplo}.

\bigskip

While I went through the proof of \DUPLO I found typos in both section $B.1$ and $B.2$. Here they had switched around on the corrupt and honest party when they recall the task of the proof. These typos has been announced to them and a fix will be made. When reporting back to them on findings like this, I add value to their work by helping to secure a better end result.


%%%%%%%%%%%%%%%%%%% Frigate %%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Frigate the \DUPLO Circuit Compiler}
\label{sec:frigate}
In this section, I will introduce how the new version of the $Frigate$ circuit compiler works. First I will introduce which requirements there are to the compiler to get it up and running. Then I will describe how the programming language used to generate the circuits works. Lastly I will cover the bug I found in the compiler, how it was done and what results this had on the \DUPLO project.

First of all, when installing the compiler some special versions of libraries are required. These laborers are not the newest updates and therefor they are required to be hold back. Following the instructions in the installation guide, which can be found via the appendix \ref{app:frigate}, and some amount of internet search, I was able to get it up and running. The hardware I have been using to run both $Frigate$ and \DUPLO, can be found in appendix \ref{app:hardware}. The standard version of $flex$ and $bison$, which ships with system I used, is newer then the one required by \DUPLO. This required, that an older versions was installed and kept back, such that no updates was made to no compatible versions. As the compilation of circuits are done once, and do not effect the compilation of the \DUPLO implementation, this is not a complete deal breaker for using $Frigate$. For future circuit compilations, this can be done using \verb|docker| via the duplo image linked in \ref{app:duplo-impl} where the right versions of $flex$ and $bison$ are installed. When I had $Frigate$ up and running I could start looking into the documentation of how it worked.

The \DUPLO $Frigate$ compiler came shipped with the documentation for the first version and was not updated, when the functionality was extended to cover the \DUPLO framework. This should not be expected as the functionality of the compilers input language was not changed, but it resulted in some time consuming trial and error for my site, as the documentation was not well written and specified. The documentation is very short and not that precise. I have not in resent time worked with circuit compilation in the way $Frigate$ required, where a higher level abstraction language was used to generate a circuit. This resulted in some hard earned experience on very small examples. 

Some of the most important and different things to take into account, learned from my time using the $Frigate$ compiler is, the possibility to do wire access. It allows you to specify exactly which and how many wires should be represent in a certain value. This is bone by the following syntax \verb|y=x{index:size}| in the $Frigate$ \verb|.wir| format. This allows for single bit inputs to be translated into higher level representations, like variables. This gave some occasional frustrations, as it is not possible to access wires based on variable inputs. As these variable inputs cannot be predetermined by $Frigate$. This makes perfect sense, since the compiler cannot know which wires should be used for the representation. This is do to the fact that, circuits are static representations and therefore to overcome, variable wire access the compiler needs to know all possible wire accesses on compile time. It the compiler could do this, it could generate components for each of these possibilities. If this approach was chosen, it will result in a huge blow up in the complexity and number of gates in the circuit. Therefore it makes perfect sense that this feature is not implemented.
A second point to remember, when working with $Frigate$ is that it do not allow for more than one level functions. This result in some restrictions when programming for circuit generation, compared to normal programming languages. This restriction makes it harder to create small functions with one single specific focus. This could be the case for generating a conditional swap gate, which we will do in section \ref{sec:con_swap}, or something similar. 
Because of this restriction it is nor possible to generate recursive functions. Because circuits are a static representation, the problem of recursive functions cannot easily be handled, since the size of the circuit can not variate based on inputs, as it is generated ahead of time. 
It is another case when looking at one level functions. I do not completely understand why this restriction was made. It may be because of the way they stitch the functions together when generating the circuit. It should be possible to handle multiple level functions via some intermediate representations. As long the depth of the function calls are static.
Another small problem I had, which was not stated anywhere in the documentation, is that $Frigate$ only allows for assignments in the main method through function calls. This gives completely sense when looking into the \DUPLO circuit file.

Otherwise the programming language used by $Frigate$ resembles the well known $C$ language. The compiler requires you to specify how many parties the functionality is used by, by the call to \verb|#parties n|. At the same time, it requires that the size of input is specified for each of the parties using \verb|input i size_i| and \verb|#output i size_o|. Other wise it allowed for definitions of constants, types, structures and imports just like in $C$ which allows for some easy readability. The programming language format used by $Frigate$ is called \verb|.wir|.

\bigskip

When the desired functionality has been implemented using the \verb|.wir| format described above used by $Frigate$, the compiler can be used to translate it in to a format the \DUPLO framework can handle. This can be done from inside the compiled \DUPLO framework, if the right versions of the libraries are installed. The compilation is done by running the following command:

\begin{center}
\begin{verbatim}
./built/release/Frigate path/to/file.wir -dp
\end{verbatim}
\end{center}

The \verb|-db| flag ensures that the right \DUPLO format is generated. This call to the compiler generates a bunch of different files with different file extensions. The file we are interested in is the file with the \verb|.wir.GC_duplo| extension. This is the file the \DUPLO framework uses as input.

\bigskip

In this section I will cover the bug found in the \DUPLO updated version of the $Frigate$ compiler. I will cover how it was found and which fix it resulted in. First of all the \DUPLO framework has a functionality, that allows for evaluation of a circuit files without setting up both parties, the $Constructor$ and $Evaluator$. This possibility gave the opportunity to specify the input values, from both the $Constructor$ and the $Evaluator$, for the computation of the circuit. This allowed me to learn the outputs, in a fast return cycle. This possibility allowed me to study the implementations of the $Frigate$ compiler and learn the programming language. This opportunity allowed me to see how the algorithms, found in chapter \ref{ch:shuffle}, behaved compared to expected while implementing them. First I tried to implement the \FY algorithm in the \verb|.wir| format. The \FY algorithm is is described in details in section \ref{sec:fisher-yates}, and can be seen as algorithm \ref{alg:fisher_yates}. During the implementation, I encountered some problems, when trying to generate the seeds from the to parties to the shuffle algorithm. Because I did not have any prior experience working with the $Frigate$ compiler, I was not able to determine if the problem arose from the implementation of the algorithm, or the compiler it self. At first the focus was on the implementation, as my lack of experience working with $Frigate$ easily could lead to errors. After a lot of modulation and debugging, it was clear that something was wrong with the compiler. During the debugging process, I created a framework that allowed me to test the different modules of the implementation one by one. It became clear during this process that something was off when using the modulo reduction. The modulo operator \verb|%| is specified in the documentation and should therefore be possible to use. Since the compiler I used was a modified version of the original $Frigate$ compiler, the posibility was that a bug could have been introduced when adding the new \DUPLO featurs. Therefore the original $Frigate$ compiler was installed to test, if that implemetation introduced the same problems with my algorithm. This idea introduced a new problme, since the original version of $Frigate$ do not support the \DUPLO circuit format. Luckely for me the \DUPLO framework interpeter has supports for another circuit file format known as $bristol$. To be able to use this file format, I wrote a parser that took the output format from the original $Frigate$ compiler, and translated that into the $bristol$ file format. This gave me the possibility to evaluate two different compiled circuit files that could tested to see if the problem also was in the original version of $Frigate$. Based on these two formats I created a test framework, to see if the two circuits generated the same output. This showed that there was a difference in the results produced, especially in the test case wher the modular reduction was used. When taking a deeper look at the problem, it became clear that not all gate types was generated during compilation, using the \DUPLO version of the $Frigate$ compiler. I was lucky that the modulo reduction triggered one of these gates. It was then discovered that multiple gates was not supported as they were forgotten during implementation.

\bigskip

\begin{table}
\centering
\scalebox{.5}{
\begin{tabular}{c c || c c c c c c c c c c c c c c c c}
$l$ & $r$ & $0$ & NOR & $\neg x$ AND $y$ & $\neg x$ & $x$ AND $\neg y$ & $\neg y$ & XOR & NAND & AND & NXOR & $y$ & If $x$ Then $y$ & $x$ & If $y$ Then $x$ & OR & $1$    \\   
\hline
0 & 0 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1    \\
0 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 1    \\
1 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1    \\
1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1
\end{tabular}
}
\caption{A table of the 16 different gate types, that can be used in a circuit of the type used in \DUPLO}
\label{table:gate_rep}
\end{table}


This discovery resulted in a fix of the new version of the $Frigate$ compiler and a complete change in the representation format used for the circuits. Now all gates in the \DUPLO format has two input and one output wire. Because of this shift in supported gate types the amount of input and output wires was removed from the file format. The representation of gates changed, from the more readable type like $XOR$, to a truth table friendly type like $0110$, for the $XOR$ gate. This change in representation ensured that all $16$ gate types was implemented. The $16$ gate types can be seen in table \ref{table:gate_rep}. The representation of the two constant $\textbf{0}$ and $\textbf{1}$ are handled as special cases, because all gates now has two input wires. For the case of $\textbf{0}$ it is handled as an $XOR$ gate, with input wires with the same value. For the case of $\textbf{1}$ it is now handled as the $NXOR$ of input wires, with the same value.

In this way by going into details and debugging my implementation of the \FY algorithm, I have contributed to the \DUPLO project by reporting my findings and allowed them to fix this problem before publishing. This has helped to secure a stronger overall research product.

They have made the changes to the compiles as mentioned above, but has not updated it to support modulo with a divisor that is not the power of $2$. This behavior of modulo is not mentioned anywhere in the documentation for the original or the updated compiler. When I discovered the problem of the modulo operator I used some time to research it, and see if a solution could be made to implement this functionality easily. During the research, I noticed that implementing the modulo reduction to some power of $2$ is simple. While the implementation of modulo with a divisor different from $2$ does not seem to be trivial. The problem was therefore left unfixed. In my implementation of \FY I use a workaround to overcome the problem, which is explained in section \ref{sec:fisher-yates}.

\bigskip

In this chapter I have covered the main idea of \DUPLO. I have argued for the security and what that will give of guarantees to my implementation. I have introduced the $Frigate$ compiler, and the problems I have encountered when using it. I have claimed my findings and added value to the \DUPLO project in multiple ways.

In the next chapter I will introduce the algorithms, used to shuffle cards in the poker implementation.


%%%%%%%%%%%%%%%%%%%% SHUFFLE ALGORITHMS %%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Shuffle Algorithms}
\label{ch:shuffle}
In this chapter, I will introduce the different shuffling algorithms studied during this project. I will introduce the ideas behind each algorithm studied and what makes it special. I will introduce why these were chosen. I will explain how they were optimized to fit better to the specific needs for a poker game. Lastly, I will compare the algorithms to see the different benefits, and based on this choose which algorithm to use in the implementation.

The permutation algorithms studied are with the purpose of shuffling card decks. It is important to chose an algorithm that ensures, that the correct amount of permutations is reached.

The first algorithm studied is the Fisher-Yates algorithm which was introduced in \cite{fisher_yates}. It may also be known as Knuth shuffle, which was introduced to computer science by R. Durstenfeld in \cite{durstenfeld} as algorithm 235. This algorithm uses an in place permutation approach and gives a perfect uniform random permutation. This algorithm is introduced in section \ref{sec:fisher-yates} and can be seen in pseudocode as algorithm \ref{alg:fisher_yates}.

The second algorithm proposed uses ideas from shuffling networks and \cite{psi} as conditional swap combined with the well known \textit{Bubble-sort} algorithm. The idea is simple and use conditional swaps gadgets which swaps two inputs based on some condition. This algorithm is introduced in section \ref{sec:con_swap} and can be seen in pseudocode as algorithm \ref{alg:con_swap}. This algorithm yields a perfect uniform permutation.

These shuffle algorithms is optimized to fit to the poker setting introduced in the section \ref{sec:poker} on poker. This is done such that it only shuffles the required cards and not the whole deck.

The implementations of these algorithms will be introduced in section \ref{sec:cir_imp} where the choises made will be discussed. At last in section \ref{sec:comp} a comparison of the algorithms is done. Here I chose which algorithm to use in the implemetation of the poker game and benchmark upon. In this section other type of shuffling networks called Bitonic shuffle network will be introduced and discussed shortly. No implementation of such a shuffle network was done.

First I will introduce the poker game used in this thesis, and another to compare the differences. This can then be used during the thesis to reflect upon how another type of poker game would have effected the outcome.

%%%%%%%%%%%%%%%%%%%%%%%%%%% POKER %%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Poker the Game}
\label{sec:poker}
I will now introduce the poker game. Poker game is a card game played in various rounds where the player draw cards and place bets. The bets are won according to a predefined list where the card constellation with the lowest probability wins. There exists many different variants of poker but only one will be chosen. The variant chosen to use in this thesis is known as 'five card draw' poker. In this study the game will be played between two parties. In this variant of poker five cards are dealt to each player in the first round. After this the first betting round occurs. Then a swap round occurs where the players have the possibility to chose how many cards to change to try to improve their hand. Then a last betting round is performed before the cards is revealed and a winner is declared.

Five card draw poker is played with a deck of 52. This poses some requirements for our shuffling algorithms. Since there are 52 cards in the deck this yields $52!$ different permutations. We require a shuffle algorithm that can produce exact these permutations to represent all the possible shuffles of the card deck. Because only the first 20 card of the deck is needed per game it is enough for the algorithm to produce a complete shuffle of these card and not the remaining 32 cards. This implies that the algorithm used to shuffle the cards only needs to produce $$\frac{52!}{(52-20)!}$$ different permutations. Since each player is dealt five card and at most can chane all these cards in the swap round. This yealds 10 card per player and therefore 20 in total.

Other variants of poker require a different amount of cards per game. One example could be if the came included tree players instead of two, then 30 cards of the complete deck would be needed. An other example could be the Texas Hold'em variant which is played by dealing two cards to each player and placing tree cards face upwards on the table. These cards are the used as a part of each of the players hand. After this a betting round is performed. This is continued by another card dealt facing upwards on the table. This is done twice before the final revelation phase where the winner is found. If the game involves two players then 4 card is dealt to the players and 5 to the table resulting in a total of 9 cards used. This implies an algorithm producing $$\frac{52!}{(52-9)!}$$ different permutations of the card deck is needed. This is also known as an $m$ out of $n$ permutation.

From here on when talking about a poker game the five card draw poker will be the reference otherwise it will be specified. This is especially interesting when looking for optimizations on the shuffle algorithms which will be introduced in chapter \ref{ch:shuffle} and when they are compared. When coming to chapter \ref{ch:implementation} this will have effect when the cards are dealt. Both in terms of the amount of data sent and the time used by the protocol.

\bigskip

I have introduced the poker game which has been implemented during the project. In the next couple of sections I will introduce the shuffle algorithms, I have chosen to implement and compare. Based on this comparison I will chose one to use in the final implementation. During the sections I will mention different optimizations that can be done to reduce the overall size of the circuits.


%%%%%%%%%%%%%%%%%%%%%%% FISHER YATES %%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Fisher-Yates}
\label{sec:fisher-yates}
\begin{algorithm}
\caption{\textbf{\textit{Fisher-Yates}} \newline
    $deck$ is initialized to hold $n$ cards $c$. \newline
    $seed$ is initialized to hold $n$ random $r$ values where $r_i\in[i,n]$ for $i\in [1,n]$.
}
\label{alg:fisher_yates}

\begin{algorithmic}[1]
\Function{Swap}{card1, card2}
\State $tmp = card1$
\State $card1 = card2$
\State $card2 = tmp$
\EndFunction
\State
\Function{Shuffle}{deck, seeds}
\For{i=1 to n}
\State $r = seeds[i]$
\State \Call{Swap}{$deck[i],~deck[r]$}
\EndFor
\EndFunction
\end{algorithmic}
\end{algorithm}

The \FY algorithm can be seen in algorithm \ref{alg:fisher_yates}. It is a well known in place permutation algorithm that given two arrays as input; one that contains the values that should be shuffled, here denoted $deck$, and another holding the values specifing how the first array should be shuffled, here denoted $seed$. These swap values from $seed$ indicate where each of the original values should go in the swap. When the algorithm runs through the first array which is supposed to be permuted it swaps the value at an given index whit the value specified by the swap value of the second array. Think of the input to be shuffled as a card deck then you take the top card of the deck and swap it with another card at a position defined by the swap value.

This implies that the algorithm takes two inputs of the same size where the one is holding the values to be permuted, $deck$ with $n$ vlause $card_i$, for $i=0,\dots,n$. The other holding the values for which the different $card_i$ in the $deck$ is to be swapped, $seed$ with $n$ values $seed_i$. If the swap values $seed_i$ from the $seed$ are not given in the correct interval the probability for the different permutations is not equally likely. Therefore it is important that the $seed_i$ values are chosen accordingly to the algorithm. The algorithm states that $seed_i$ is chosen from an interval starting with its own index $i$ to the size $n$ of the $deck$. This gives exactly the number of permutations required as $card_1$ has exactly $n$ possible places to go. $card_2$ has $n-1$ possible places and so forth until the algorithm reaches $card_n$ which has no other place to go. Since $seed_i\in[i,n]$ we have $n!$ because $i$ runs from $1$ to $n$ which should be the case as described in section \ref{sec:poker}.

If the $seed_i$ values contained in $seed$ is not chosen for the right interval but instead all is chosen from $1$ to $n$ we would end up having a skew on the probability of the different permutations. As $card_i$ in this case has $n$ possible places to go, this yields $n^n$ distinct permutations. This introduces an error into the algorithm as there should only be $n!$ and as $n^n$ is not divisible by $n!$ for $n>2$. This result in a non uniform probability of the different permutations. The same is the problem if $seed_i$ is not chosen from $[i,n]$ but instead $]i,n]$ such that the own index is not in the interval. By introducing this error to the algorithm the empty shuffle is not possible. In other words it is not possible to get the same output as the input. Which does not give the desired uniform distribution of permutations.

\bigskip

In case of the poker game we need $52!$ permutations. If all $seed_i$ is chosen from $[i;52]$ we would get $52^{52}$ possible permutations. As described $52^{52}$ is not divisible by $52!$ since $52>2$. If $seed_i$ instead is shosen from $]i;52]$ we get $(52-1)!$ permutations which is neither devisible by $52!$.

\bigskip

As described in section \ref{sec:poker} no more then a permutation on the first 20 cards is needed. Which means that we only need the $\frac{52!}{32!}$ specific permutations out of the total of $52!$ different permutations. Doing a $m$ out of $n$ permutation using the \FY algorithm is straight forward. Instead of running through $n$ swaps indicated by the size of $seed$ it is enough to run through $m$ swaps. In out case resulting in the input $seed$ only need to have size $20$ and therefore the for-loop seen in algorithm \ref{alg:fisher_yates} in the shuffle function needs to have fewer iterations. Those giving us a full permutation on the first $m$ indexes of $deck$.

\bigskip

\begin{figure}
\centering
\scalebox{1.5}{\input{figurs/fisher-yates}}
\caption{Fisher-Yates algorithm in action: In this figure a 9 out of 52 shuffle has been completed to ilustrade how the algorithm works. First 1 is swpaed with 1. Then 2 is swaped with 51. 3 with 14. 4 with 20 and so on until the first 9 numbers has completed a full permutation. Resulting in 1, 51, 14, 20, 10, 37, 9, 33, 6.}
\label{fig:fisher_yates}
\end{figure}

In figure \ref{fig:fisher_yates} it is possible to see the \FY shuffle in action. Here the first $9$ cards of a sorted deck is shuffled according to the giving seed. Running the algorithm on these inputs give the $9$ first cards $1,~52,~14,~20,~10,~37,~9,~33,~6$ as output. It is interesting to notice that $37$ in the seed twice. Since the algorithm permute the imput $deck$ the value $37$ will not be in the output twice. We see that $6$ is swapped in the second time the seed $37$ is used. This is because the first time $6$ and $37$ was swapped. This illustate that it is possible for a $card$ to be swapped multible times.


%%%%%%%%%%%%%%%%%%%%% SHUFFLE NETWOKS %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Shuffle Networks}
Shuffling networks or permutation networks has a lot of resemblance to sorting networks. The idea behind this type of networks is that they consist of a number of input wires and equally many output wires. These wires go through the entire network. On these wires a swap gadget is plased. This gadget is constructed such that if a condition is satisfied the input on the two wires are swapped. By placing these swap gadgets correctly on the input wires it is possible to get a complete uniform random permutation of the input on the output wires. The swap gadgets are created according to \cite{psi} as figure 3.

Applying such a shuffle network in the setting of a poker game is simple. The input to the shuffle algorithm is the $deck$ that we want to shuffle and the output is the shuffled $deck$. The more interesting part is how to place the swap gadgets to ensure that the right number of possible permutations is satisfied. There are many different shuffle algorithms that can be implemented using shuffle networks. The one I have looked into and implemeted builds on ideas from \cite{psi} where they introduces the conditional swap gadget. The algorithm is a combination of the well known $bubble\text{-}sort$ algorithm and the conditional swap.

\bigskip

In the next section I will introduce the conditional swap algorithm, which can be seen as algorithm \ref{alg:con_swap}.

\bigskip

\paragraph{Conditional Swap:}
\label{sec:con_swap}

\begin{algorithm}
\caption{\textbf{\textit{Conditional swap}} \newline
    $deck$ is initialized to hold $n$ cards $c$. \newline
    $seed$ is initialized to hold $\frac{n^2}{2}$ random $bit$ values where $bit_i\in[0,1]$ for $i\in [1,\frac{n^2}{2}]$.
}
\label{alg:con_swap}

\begin{algorithmic}[1]
\Function{ConditionalSwap}{bit, card1, card2}
\If{bit equal 1}
\State $tmp = card1$
\State $card1 = card2$
\State $card2 = tmp$
\EndIf
\EndFunction
\State
\Function{Shuffle}{deck, seeds}
\State $index = 0$
\For{i=1 to n}
\For{j=n-1 to i}
\State $index = index + 1$
\State $bit = seeds[index]$
\State \Call{ConditionalSwap}{$bit,~deck[j],~deck[j + 1]$}
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\end{algorithm}


The conditional swap algorithm takes two inputs; the first input is an array, denoted $deck$ of $n$ cards $card_i$ for $i=1,\dots,n$, and the second an array $seed$ of size $l=\frac{n^2}{2}$ bits $b_j$ where $j=1,\dots, l$. The algorithm creates $n-1$ layers of conditional swap gadgets. The first layer contains $n-1$ conditional swap gadgets. The second $n-2$ and so on until the las layer consisting of one gate. Each layer is constructed such that a swap gadget is placed on two adjacent input wires. Each of these gates overlap with one of the inputwires at the adjacent swap gadget. This is illustarated in figure \ref{fig:con_swap}. The layers are stacked in such a way that the first input wire is only represented in the first layer. Thereby is the first value on the first output wires determined by the first layer of swap gadgets. Resulting in the first input $card_1$ has $n$ places to go. The second layer determines which output $card_2$ will have and so on. Continuing this way until reaching the last layer where the two last outputs $card_{n-1}$ and $card_n$ will be determined. This gives us a shuffle algorithm with a perfect shuffle and $n!$ different permutations as decired.

If each layer of the swap gadgets are not decreasing by one on the amount of swap gadgets this algorithm suffers the problem of producing $n^n$ permutations. Which is not devisible by the decired $n!$ permutations. This resulting in a skew of the probability on the different permutations such that the propability of each permutation is no longer uniform.

\bigskip

Again some optimization can be done to the algorithm since we only need a $m$ out of $n$ permutation. This can be done by letting the outer loop of algorithm \ref{alg:con_swap} run for $m$ iterations instead of $n$. This yields $n$ possible values for $card_1$, $n-1$ possible values for $card_2$ and so one until $n-m$ values for $card_{n-m}$. This is exactly the amount of permutation we require for our optimized algorithm as this gives us $\frac{n!}{(n-m)!}$. Which is enough for our poker implementation as described in section \ref{sec:poker}

\bigskip

\begin{figure}
\centering
\scalebox{1.5}{\input{figurs/con_swap_fig}}
\caption{Conditional swap algorithm in action: In this figure a 9 out of 52 shuffle has been completed to ilustrade how the algorithm works. Each bit in the $seed$ indicate if a gate should be swapped. Since the size of $seed$ is so big I have tried to ilustrate which wire each value is located at before moved in a layer resulting in 1, 51, 14, 20, 10, 37, 9, 33, 6.}
\label{fig:con_swap}
\end{figure}

In figure \ref{fig:con_swap} a run of algorithm \ref{alg:con_swap} can be seen Here a $9$ out of $52$ variant is used. It can be seen that the inputs $deck$ is soreted and holds the values to be shuffled and $seed$ which are binary and indicates if two values should be swaped. The first $52$ bits of the $seed$ decides if the first $card$ values should be shuffled. Which is not the case in this run. Then the next $51$ bist from $seed$ indicate that $51$ should be swapped all the way accross to the wire repecenting the second out card. This implies that all cards $51$ passed on its way will now be on the right adjacent wire to where it was prior to the swap. That is why the third output $card$ with value $14$ starts at wire index $15$ and output wire four with value $20$ starts at wire index 21. So the algorithm continiues until it outputs the first $9$ cards shuffled as $1,~51,~14,~20,~10,~37,~9,~33,~6$.


%%%%%%%%%%%%%%%%% CIRCUIT IMPLEMENTATION %%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Implementation}
\label{sec:cir_imp}
Because the \DUPLO protocol was chosen as the $MPC$ protocol to use in this study the first hurdel was to generate the circuits that should handle the shuffling of the cards. Since circuits become rather complex when trying to implement functions it was important to have a compiler that could translate the algorithms into the desired circuit representation. Luckly the \DUPLO project came shiped with a compiler for generating circuits with the right format. Therefor before staring to implemt the shuffle algorithms I had to read up on the documentation for the compiler, which can be found by following the descriptions in appendix \ref{app:frigate}. The documentation was from the first version of the $Frigate$ compiler which was extended during the \DUPLO project generate the decired \DUPLO format. An introduction to the $Frigate$ compiler created in the \DUPLO project can be fondu in section \ref{sec:frigate} and the codebase is introduced in appendix \ref{app:frigate}. Because it was a long time since I last had worked with circuits and the documentation of the incorporated functionality of $Frigate$ I used some time getting up to speed. Much of this time was by trial and error which gave me some hard earned experience throug small examples.

\bigskip

Before going into details on the implementations a link to the sourcecode can be found in appendix \ref{app:circuit-impl}. In the implementation of the two shuffle algorithms there are five different functions was implemented as different modules that could be used. Both shuffle algorithms \FY and \CS makes calls to the function \verb|initDeck|. Which initializes a hardcoded representation of the card deck which is to be shuffled when evaluating the generated circuit. This is done by a for-loop inserting the values of the deck on the right wires. In the implementation $6$ bit variables is used for the representation of each card, as $6$ bist allows for $64$ different representations, because $2^6=64$. Which is enough to represent each unique card in the deck. It is importand to notice that the variable indexing the start position of every card needs a representation with at least $9$ bits to hold the correct value, since $\lceil \log_2(52\cdot 6)\rceil=9$. If only $6$ bits were used for indexing only wires up to opsition $63$ could be assigned and not all $312$, as required since $52\cdot 6=312$. Therefor $9$ bit is used for this variable.

\bigskip

Then looking into the rest of the stucture of the \CS algorithm we see that the first function used is the \verb|xorSeed|. This function handles the $XOR$ of the $seed$ recieved from the two parties. This is a straightforward implementation using the build-in $XOR$ function \verb|^|. After this the calle to \verb|initDeck| is done shuch that the result for the two functions can be fead into the shuffle algorithm. Such that the last function used in the \CS algorithm is the \verb|shuffleDeck| function. This is the function handling the actual shuffling. This is implemented using two for-loops; one for constructing the layers in the network, and another for generating the swap gadgets in each respective layer. Folowing the structure of algorithm \ref{alg:con_swap} we ensure that we are ending up with an algorithm producing the right amount of permutations according the discussion made in section \ref{sec:con_swap}. Using the optimizations proposed in the same sections results in a clear reduction in the number of gates, as seen in table \ref{table:con_swap_comp}. Most important we see a $62\%$ reduction in the non-free gates on the optimized version.

\begin{table}
\centering
\begin{tabular}{l || r r r}
Gate Type      & Non-optimized  & Optimized & Difference($\%$)    \\
\hline
Free Gates     &  $97753$       & $39001$   & $60$ \\
Non-free Gates &  $47739$       & $18363$   & $62$ \\
\hline
Total          & $145491$       & $57364$   & $60$
\end{tabular}
\caption{\CS: Comparison of the non-optimized and optimized versions of the algotithm. The comparison is done on the amount of each gate type in the compiled circuit.}
\label{table:con_swap_comp}
\end{table}

\bigskip

In case of the \FY algorithm the things stack up a bit differently. The first function in this case is the \verb|correctSeed|. The function takes the $seed$ from the two parties and correct them as described in section \ref{sec:fisher-yates}. At first each of the inputs are splitted up into representations of $6$ bits such that they each hold $52$ values, $seed_{C_i}$ for the $Constructors$ and $seed_{E_i}$ for the $Evaluator$. Then the new input reprsentations are added such that $seed_{C_1}$ is added with $seed_{E_1}$. This ensures that the new value $seed_i$ is at most $2\cdot (2^6 - 1)$ because of the representation. Since the addition of two $6$ bit values can not be guaranteed to fit inside another $6$ bit value a representation with more bits is used to store the resulting value.
The idea was to use a modulo reduction on $seed_i$ to gurantee that it was inside the intervall describetd in section \ref{sec:fisher-yates}. Since the modulo reduction implemented in $Frigate$ only supports divisors that is a power of $2$ the modulo reduction in $Frigate$ can not be used, because $seed_i$ is not guaranteed to have this property. I used a lot of time to figure out that the $Frigate$ modulo operator only worked on powers of $2$. This implemetation detail was not specified anywhere in the documentation. The first idea was to fix the problem by implementing a modulo function that I could use instead. I therfor put some research time into this problem, but it is to be rather complex to achive. Therefor another solution was chosen to overcome the problem. Since the input $seed_{C_i}$ and $seed_{E_i}$ to the functionality is assumed to be in the right intervalls the solution was to subtract the boundray of the interval $I_u=52-i$ from $seed_i$ if this exceets $I_u$. Doing it this way it yealds a resulting value $seed_i$ in the right intervall. This is do to the fact that $seed_{C_i}$ and $seed_{E_i}$ can at most be $I_u$. This ensures that $seed_i$ is at most $2\cdot I_u$. Then $seed_i - I_u$ is guaranteed to be at most $I_u$.
In the implemetation this was done by introducing an $if$ statment checking if $seed_i$ exceeded $I_u$. It is nothworthy to mention that all values have had an unsigned representation until now. But since the comparison of to values needs a signed representation as stated by the documentation $seed_i$ was converted. This corrections to the implemetations now ensures that the randomness given to \verb|shuffleDeck| has the right form. But only if $seed_{C_i}$ and $seed_{E_i}$ are inside the right intervall $[0;I_u]$.

The second function used in the implementation is the same as in the case for the \CS algorithm where the \verb|initDeck| function is called to initialize the representation of the $deck$ which is to be shuffled. The last function called is the \verb|shuffleDeck| function which is different from the one from the \CS algorithm. This function consist of an outer for-loop that runs through the cards $card_i$ of the deck. Because circuits are a static representation as disscused earlier in section \ref{sec:frigate} it is not possible to assign a wire value based on a variable input. Therefor this for-loop generates layers of conditional swap gadgets. Resulting in $52-i$ swap gadgets in each layer, for $i=0,\dots, 51$. This is represented by the inner for-loop. In this way a composed gadget is generated for each $card_i$ such that the $card_i$ can be swapped with any other $card_j$, where $j=i,\dots,51$. This composed gadget is a composition of $52-j$ desitinc swap gadgets. Such that the desired propability is reached as described in section \ref{sec:poker}.
Both an optimized and non-optimized version of the algorithm was implemented to see how big the gain of the optimization was. This can be seen in table \ref{table:fy_swap_comp}, where we see that the optimization result in a $40\%$ decresae in the number of non-free $XOR$ gates.

\begin{table}
\centering
\begin{tabular}{l || r r r}
Gate Type      & Non-optimized  & Optimized & Difference($\%$)    \\
\hline
Free Gates     & $61806$        & $37433$   & $39$ \\
Non-free Gates & $37344$        & $22357$   & $40$ \\
\hline
Total          & $99150$        & $57790$   & $42$
\end{tabular}
\caption{\FY: Comparison of the non-optimized and optimized versions of the algotithm. The comparison is done on the amount of each gate type in the compiled circuit.}
\label{table:fy_swap_comp}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%% COMPARISONS %%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Comparison}
\label{sec:comp}

In this section I will try to compare the two algorithms on their internal structure. I will compare the algorithms based uppon their gate composition and based on that choose which one to continiue with in the implementatin of the poker game. When comparing the algorithms I use the optimized versions as it would be one of these that will be used because of their gain in the number of non-free $XOR$-gates.

\bigskip

The first we will look at is the input to the \verb|shuffleDeck| functions. The both take the $deck$ as input, which in both cases is generated by the function \verb|initDeck|. This does therfore not yeald any difference to the algorithms. Then when looking at the $seed$ it is clear that there are some differences. Both in terms of representation and in size. First looking at the representation of $seed$, in \FY $seed_{FY}$ and \CS $seed_{CS}$. The $seed_{FY}$ is a representation of $20$ values $seed_{FY_i}$ in the interval $[0;52-i]$, for $i=1,\dots, 52$. Where $seed_{CS}$ does not have any abstrac representation and therefore $seed_{CS_i}$ has the binary representation $[0;1]$. The difference in the representations is one reason why we se a difference in the size of the $seed_{FY}$ and $seed_{CS}$ in terms of bits. Where the size of $seed_{FY}$ is $112$ since $6$ bists are used for the representation of the $20$ seed values. The size of $seed_{FY}$ is $830$ because one bit is needed per swap gadget, which is $\sum_{i=52-20}^{51} i$. As we see it is also the way the algorithm uses the $seed$ that effect the size. Where the \FY algorithm constructs composed gadgest consisting of multiple swap gadets the \CS algorithm only constructs swap gadgets. Even thoug the algorithms has different approches to generate the swap gadgets they end up generating the same amount of swap gadgets. Because \FY generates $19$ composed gedgest $CG_i$ consisting of $52-i$ swap gadgets, for $i=1,\dots,19$. Yealding the same number of swap gadgets as in \CS.

If we then instead turn our attention to the way the algorithms handle the $seed$ before they are fead to \verb|shuffleDeck| we se some big differences. Because both algorithms takes $seed_C$ and $seed_E$ as inputs from $Constructor$ and $Evaluator$ the algorithms needs to generate one single $seed$ that can be used by \verb|shuffleDeck|. This adds an overhead to the algorithms. This is not much for the \CS algorithm since it can use the $XOR$ function because it uses one bit of randomness at a time. As described in section \ref{sec:fisher-yates} this is not the case for \FY since it uses $6$ bits of randomness $seed_i$ at a time. Because there is the restriction on the $seed_C$ and $seed_E$ and the $seed$ input to \verb|shuffleDeck| in \FY the overhead added is more. The split-up of $seed_C$ and $seed_E$ into $seed_{C_i}$ and $seed_{E_i}$ does not add any overhead, but the addition of these does. Also the check to test if $seed_i$ is greather then $I_u$ and the subtraction adds an overhead to the overall circuit. The differences can be seen in table \ref{table:alg_preprocess_overhead} where it is clear that \verb|xorSeed| adds significantly less overhead to the circuit compared to \verb|correctedSeed|. 

\begin{table}
\centering
\begin{tabular}{l || r r r}
Gate Type      & \verb|correctSeed| & \verb|xorSeed| & Difference($\%$)    \\
\hline
Free Gates     & $4347$             & $1661$         &  $62$ \\
Non-free Gates & $1873$             &    $2$         & $100$ \\
\hline
Total          & $6220$             & $1663$         &  $73$
\end{tabular}
\caption{Comparison of the overhead added to the algorithms by handling the $seed$'s. The comparison is done on the amount of each gate type in the compiled circuit.}
\label{table:alg_preprocess_overhead}
\end{table}

We see that the \verb|xorSeed| has two non-free gates, which is strange since it only does $XOR$ as should be free. This is because of the bit constants \textbf{0} and \textbf{1} which are implemented using $AND$ or $NADN$ with both inputs comming from the same wire. Therefore will every circuit generated with the compiler have these two non-free $XOR$ gates.

\bigskip

When looking in to the overall composition of \FY and \CS we get the results as seen in table \ref{table:circuit_comp}. We see that \CS is overall $4\%$ bigger in terms of the amount of gates than \FY. On the more important comparison is that \CS has $18\%$ less non-free $XOR$ gates. Therefore is the \CS algorithm the one that will be used in the implementation of the poker game.

\begin{table}
\centering
\begin{tabular}{l || r | r | r}
Gate Types     & \FY     & \CS     & Difference(\%) \\
\hline
Free Gates     & $37433$ & $39001$ & $-4$   \\
Non-free Gates & $22357$ & $18363$ & $18$   \\
\hline
Total          & $59790$ & $57364$ &  $4$
\end{tabular}
\caption{Compariason of the \FY and \CS algorithms after compilation to \DUPLO circuits. The comparison is done on the amount of each gate type.}
\label{table:circuit_comp}
\end{table}

As a note to the comparison it shouls be mentioned that some of the variables used in \verb|correctedSeed| are bigger in terms of bit size than needed. But since this is only a fraction of the $1873$ non-free gates seen in table \ref{table:alg_preprocess_overhead} this wouls not change that \CS has less non-free gates then \FY.

\bigskip

At last I will give a short comment on another possible shuffle algorithm that could have been used. This other types of sorting networks that the one studdied in section \ref{sec:con_swap}. In \cite{psi} they also uses a algorithm known as the $Bitonic$ merge sort algorithm. Such an algorithm is constructed of what is known as $half-cleansers$. These $half-cleansers$ are constructed such that the input is guaranteed to have one peak $p$, $i_1\leq \dots \leq p \geq \dots \geq i_n$. Then the output is half sorted such that the highest values are in one of the two halfs. Resulting in a algorithm that can sort any input. This guarantees that one input $seed_i$ can every other place. If the conditional swap gadget is used then it can be used as a shuffle algorithm instead of a sorting algorithm. This type of sorting network generates a circuit of size $O(n\cdot log(n))$ which is better then what the \CS and \FY algorithms can aquire which is $O(n^2)$. But as argued earlier the \CS and \FY algorithms are easily optimized. This seems not to be the case for a $Bitonic$ shuffle network.

As a result of this we see that for some card games it can be better to use another algorithm then the ones studied in this thesis since it may outperform them. We now know that a $Bitonic$ algorithm would produce a smaller circuit that \FY and \CS but since the two algorithm are easy to optimize such that they produce a relative small circuit. It is not clear that a $Bitonic$ algorithm will produce a circuit that is smaller. This implies that there will ba a cross over at some point where it is better to shuffle a complete deck then only parts of it as is done in our case. This can even be the case when only a part of the deck is needed.


%%%%%%%%%%%%%%%%%%%%%%%% POKER IMPLEMENTATION %%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Poker Implemetation}
\label{ch:implementation}
The main idea of this chapter is to introduce the different stages during the implementation. Here I will introduce the different problems I have encountered and how I have chosen to overcome those.

In section \ref{sec:poker_imp} I describe the process of implementing the poker game using \DUPLO. First I discuss the setting in which the implementation is done. Then an introduction to the decissions made and woh the interaction with the framework was done.

In section \ref{sec:bechmarking} I introduce the testing that was done on the implementation. I explain what and how it was done. The implementation was tested on several parameters to try to compare the perfoemance against what could be expected of a real world online poker game. The inplementation was tested against the amount of data sent and time consumption in different phases. When the optimal setting was found this was used to test the effect of network latency and bandwith on the protocol. All test were done per simountaious shuffled deck.

%%%%%%%%%%%%%%%% 2PC POKER IMPLEMENTATION %%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Game}
\label{sec:poker_imp}
As described in section \ref{sec:duplo_framework} where the structure of the framework was introduced. This structure is what every implemetation using the \DUPLO protocol needs to have. In the next part I will introduce how this was used to implement the poker game in this project.

\bigskip

\begin{figure}
\centering
\input{figurs/poker_setting}
\caption{The two different settings discussed to implement. The one on the left where the $Constructor$ and the $Evaluator$ also are the players and the one on the right wher they act as servers where players connect and then localy construct output based on output from the servers.}
\label{fig:poker_setting}
\end{figure}

Before starting on the implemetation it is inportant to decide which setting of the poker game should be studdied. Two different settings was proposed and discussed, these can be seen in figure \ref{fig:poker_setting}. The first is one where the $Constructor$ and $Evaluatr$ act as players of the poker game themselves. They will play against each other and each decide on which and how many cards should be changed. The other setting is where the $Constructor$ and $Evaluator$ act as servers where players connect to. These players will act as clients connecting to both the $Constructor$ and $Evaluator$. Here the $Constructor$ and $Evaluator$ will run the protocol as described, but use inputs from the clients. The first one is the one chosen mainly because of the simplicity and timelimit of the project. The other setting has some interesting features which I will mention here. The second setting resembles what is used in real world online poker today. Today a player connects to a server which handles the shuffleing and dealing of cards. Then instead of connecting to one server which is not completly trusted the player connects to two servers which runs a secret share of the \DUPLO protocol. Then the player will recieve a share from each party and reconstruct the computed output. This setting distribut the trust issiue with the setting used to day. It could be the example that one of the serves in the \DUPLO setting is a State authorized server in which the palyer then would put its trust. Then game makers is then required to use the protocol against this server to be allowed to sell games in that contry. It will alow for a distributed instead of a single piont trus issiue. In the second setting there are no limits to how many playes could connect to the servers to play a game of poker. In this way the $2PC$ is not a restriction for the amount of players. This setting requiers a way of handling authentisity between the players, the $Constructor$ and $Evaluator$. This is needed to encure that non of the players sends different inputs to the $Constructor$ and $Evaluator$, and to encure that the $Constructor$ and $Evaluator$ does not send different outputs to the players. This is not a simple task to overcome, therefor the first setting was chosen.

The way \DUPLO is constructed it allows for preprocessing of the circuits, such that the right informtion is at the right party before evaluation. The overall protocol can be catogorized in 3 different main phases. The first phase is the $Preprocess$ phase which consist of the framework calls from section \ref{sec:duplo_framework}; \verb|Connect|, \verb|Setup|, \verb|PreprocessComponentType|, \verb|PrepareComponets| and \verb|Build|. The next phase is the $Evaluation$ phase which calls the \verb|Evaluate| framework function. The last phase is the $Online$ phase which consists of the \verb|DecodeKeys| calls. Building the protocol this way allows for an intens $Preprocess$ phase where a lot data is processed and communications is done. This allows for a faster $Evaluation$ phase and results in a small overhead when running the $Online$ pahse.

\bigskip

I will now describe the implementation of the poker game. First of all we need to both implementa a $Constructor$ and an $Evaluator$. These runs the protocol in parallel with the same framework calls, but holds different information during the phases. First we read the composed circuits in to both parties such that they know which functionality is to be computed. 
Then the first interaction between the two parties is when the \verb|Connect| call is done. On the $Constructor$ site this generates the server functionality which the $Evaluator$ connect to with this call. 
After this a call to \verb|Setup| was done to initilize the commitment scheme used by the protocol.
Then a call to \verb|PreprocessComponetType| is done on each of the subcircuits. Given the subfunctions and the number of garbled copies to generate.
Efter this a call to \verb|PrepareComponets| is done, given the number of input wires in the circuit. It the generates the key authenticators to securly transfter the input keys and attach all output authenticators.
At last the circuit are generated by the call to \verb|Build|. Given a representation of the composed circuit, this call genrates a garbled representation of the prepared components such that they compute the functionality specified by the composed circuit.
No special input is given to any of the parties during the phase except of the circuit represention of the functionality to be computed. Therefor this will be denoted the $Preprocess$ phase. As these calls can be done done ahead of time and without knowing anything other then the functionality to compute.

The next phase is the $Evaluate$ phase, where the evaluation of the garbled circuit is done. Before the call to \verb|Evaluate| can be done each of the parties need to generate their inputs to the shuffle algorithms. Since the shuffle algorithms always shuffles the same values the $deck$ is harcoded into the circuit. Therefore it is sufficient for the parties to provide the $seed$ for the algorithm. This is done by generating $16$ bytes of random data. This data is then used as a seed for a pseudo random generator producing the $830$ bit randomness used for each $deck$ that needs shuffled. This generated randomness is used as the input to \verb|Evaluate|. The function also takes an empty array as input to store the garbled output.

The last phase is the $Online$ phase it is here the calls to \verb|DecodeKeys| is done. This phase is run for each game played. The amount of games possible is specified in the number of simuntainiusly shuffled decks. In this phase the $Constructor$ and $Evaluator$ must first agree on which outputwires should be opened to which party. Therefor the first they do is to generate an array containing the wire indexes to be opened to the $Constructor$ and to the $Evaluator$. These are then opened by a call to \verb|DecodeKeys|. The values are then translated into card representations and displayed to the players. 
The translation from values $n\in \{1,\dots,52\}$ to cards $(v,s)$, where $v$ is the value and $s$ is the shade of the card, are done by letting $v=(n \mod 13)+1$ and $s \mod 4$. This yealds no collitions on $(v,s)$ since $13$ and $4$ has no common multiplum less then $52$. 

When drawing the first hand the $Constructor$ is always dealt the first five cards from the deck. The $Evaluator$ are dealt the five cards starting from index $10$ to $14$. This is the most optimal way to deal the cards as this requires the least calls to \verb|DecodeKeys|. This does not change the propability of the cards dealt. As known for real world card games one or two cards are normaly dealt at a time, this is propably done because the shuffle algorithm doeas not have a uniform distribution. But has a skew such that sequences of cards are more likely to repeat in the next game. This is not the case for our shuffle algorithms, since they have a uniform propability distribution on the output.

After the first hand have been dealt an interface is displayed to the players such that they can choose which cards to change. This is done using a terminal interface where the user inputs; $0$ if no cards needs to changes, $1$ if the first card should be changed, $2$ for the second and so on. If multiple cards is to be changes this is done by seperating the card indexes with a comma $','$ like $4,5$. To allow for a new hand to be dealt with the specified cards changed the parties first sents the amount of cards thay want to change. The they sent the indexes of the cards they want to change. Now each party knows which wires should be opened. The old array holding the index of output wires is updated to hold the new index wires. Then the second and final hand is opened by a call to \verb|DecodeKeys|. The card are translated and  displayed to the parties. The cards with indexes from $5$ to $9$ is reserved for the $Constructor$'s second hand, while the cards with indexes from $15$ to $19$ is reserved for the $Evaluator$. Opening the last hand this way adds an overhead since one card may be openend in both the first and second hand. On the other hand this allows for less communication before the last revilation round in the game.

The last round of each game is the round where the revelation of the oponents hand is done. This is done without any communicatin other than a last call to \verb|DecodeKeys|. The input to this last call is done by switching the inputs for the $Constructor$ and $Evaluator$ as they already know which wires was openend to the oponent in the last hand. By opening the oponents card this way we ensure that the oponenet does not learn the cards which were discarded.

At last when all the decks are played the statisitcs are writen to the log files. This is the timings and amount of data send by the different calls. This data is used in the section \ref{sec:bechmarking} to discuss the effeciency of the \DUPLO protocol in the setting of a poker game.

\bigskip

A small note on the leak of information when communication indexes for \verb|DecodeKeys|. The oponent always know how many and which cards are changed because the parties needs to agree on which wires to open, but this is not any different from real life poker. Therefor this leak of information should not be considered a security problem.

\bigskip

Another note on the \verb|DecodeKeys|. When implementing the poker game I experienced problems with the call to \verb|DecodeKeys| when trying to do unique openings to the single parties. It was later discovered that an update to the protocol had only been done on the oneside of the protocoal and not the other.


\section{Benchmarking}
\label{sec:bechmarking}

In this section I will introduce all the testing that have been done on the poker implementation. This has been done to see if a implementaion using a $2PC$ framework can reach runningtimes close to real life online poker.

To do benchmarking a local machine was used. The hardware setup can be found in appendix \ref{app:hardware}. This setup was used to ensure a stabile environment such that no newtwork latency chunks would obstruct the results. To handle the experience of real networks a script was used to simulate bandwidth and latency. The bandwith was set to 1 Gb/s during all test. This is in the high end compared to most bandwith connections found in Denmark, but was choosen to get a faster roudtrip on the test environment. The latency was changed during the testing to see how it effected the implementation.

In the implemntation different flags was implemnted to allow for an easy change of the setup. The flags implemented were; \verb|-f| for specification of the circuit file to use, \verb|-e| for the number of threads to use in the different phase, \verb|-n| for the number of parallel shuffles in the circuit, \verb|-i| to allow for interaction or not in the card change phase, \verb|-ip_const| for specifing the ip address of the constructor, \verb|-p_const| for specifing the port the $Constructor$ is listening on and lastly the \verb|-d| flag for ram only mode, where the computation is done without writing anythig to disk.

\bigskip

The first tested was the timing of each shuffle done when multiple was done in parallel. This was done to see how the approch to cut and chose in \DUPLO effected the poker implementation. This allows us to see if we reach a optimum of the number of simuntainious shuffles. To do this different circuits was generated and compiled to mesure the timings. Because the \DUPLO framework do not allow for soldering of \DUPLO format circuits, the ciruit file used should contain all simuntainiously shuffle of decks. Therefor different variants of the \CS algorithm was made where 1, 10, 100, 1000 and 3000 simuntainius decks was shuffled. The 3000 was choosen as a maximum since the memory limit was exceede on the hardware when more was tested. These variants of circuits was all compiled following the instructions in appendis \ref{app:frigate}. The \CS implementations from section \ref{sec:con_swap} was used because it has the least amount of non-free $XOR$ gates and therefor should be faster then \FY . This is was is shown in table \ref{table:circuit_comp}.

A bash script was setup to allow for automatic testing of all these different circuits, this is explained in \ref{app:test-res}. This script ensured that 10 timings was done for each of the circuits to guarantee more fair timing when taking the average. All the timings were loged and can be found via appendix \ref{app:test-res}. One timing was removed from the $Constructor$ since it differentiated form the rest. This is the timing for the first run of the poker game where the timing of \verb|Setup| was long, this is because of the time it takes to start the $Evaluator$ and prepare the bandwith. These tests was done with a latency of $50$ms. This was found to be a fair latency based on pinging different ip addresses in europa as seen in table \ref{table:ping}. 

\begin{table}
\centering
\begin{tabular}{l || r}
Homepage & Avg. latency(ms)    \\
\hline
google.dk    &  18    \\
google.com   &  54    \\
au.dk        &   2    \\
uoa.gr       & 132    \\
uzh.ch       &  41    \\
univie.ac.at &  36    \\
\hline
Total avg.   &  47
\end{tabular}
\caption{Ping: Timings of network latency to different locations in europa.}
\label{table:ping}
\end{table}

When dicussing the results I will refer to the phases as described in section \ref{sec:poker}, $Preprocess$, $Evaluate$ and $Online$. This is done to reduce the amount of information in the figures auch that only the most necesary information is precent.

\bigskip

\begin{figure}
    \centering

    \begin{subfigure}{\textwidth}
        \centering
        \scalebox{.7}{
        \includegraphics[width=\textwidth]{figurs/const_kb_log_xy.eps}
        }
        \caption{}
        \label{fig:const_kb_plot}
    \end{subfigure}

    \vspace*{0cm}

    \begin{subfigure}{\textwidth}
        \centering
        \scalebox{.7}{
        \includegraphics[width=\textwidth]{figurs/eval_kb_log_xy.eps}
        }
        \caption{}
        \label{fig:eval_kb_plot}
    \end{subfigure}

    \vspace*{0cm}

    \begin{subfigure}{\textwidth}
        \centering
        \scalebox{.7}{
        \includegraphics[width=\textwidth]{figurs/total_kb_log_xy.eps}
        }
        \caption{}
        \label{fig:total_kb_plot}
    \end{subfigure}

    \caption{Data sent: Comparison of $Constructor$ and $Evaluator$ in $kb$'s sent to the other party. (a) $Constructor$: Accumulated data sent per deck shuffled on a duble logarithmic scale. (b) $Evaluator$: Accumulated data sent per deck shuffled on a duble logaritmic scale. (c) $Total$: Accumulated data sent per deck shuffled on a duble logaritmic scale.}
    \label{fig:mesurement_kb}
\end{figure}

The first we will look at is the amount of data send in $kb$ per shuffled card deack as seen in figure \ref{fig:mesurement_kb}. We see the accumulated dats sent per deck shuffled. The data is represented on a duble logaritmic scale. It is easy to see that as more simuntainiously shuffles are done the least data is sent. This implies that the most data sent is the overhead of setting up the protocol. As we see it is har to distinguish the different lines on the plot. This is because the $Preprocess$ phase is the one where the most data is sent. Relative to this nearly no data is sent in the $Evaluate$ and $Online$ phase. Remembering har it is only the input to the functionality that is sent in the $Evaluate$ pahse. In the $Online$ pahse we call \verb|DecodeKeys| three times and therefore is only these keys that are sent. Where as in the $Preprocess$ phase the information of the garbling, soldering and authentication is done. Therfore more data is sent.

In figure \ref{fig:eval_kb_plot} we see that the line is flattening out indicating that there are not much more to gain on the $Evaluator$ site in terms of $kb$ sent, by shuffleing more decks simuntainious. Looking at figure \ref{fig:const_kb_plot} we see a different tendency where the plot is still decreasing indicating that some gain can still be done on the $Constructor$ site. This may indicate that more than $3000$ simuntainus shuffles can benefit on the amount of data sent as seen in \ref{fig:total_kb_plot}, which is still decreasing. Looking at the scale on $kb$ axis it is obvious that it is the $Constructor$ that sents the most data and therefore the one that require the most simuntanious shuffles to bring the overhead of doing $2PC$ down.

This is excatly as expected before doing the experiments. The amount of $kb$ sent would decrease as more shuffles were done because of the overhead of doing $2PC$. Even going beond the $3000$ shuffles seems to give a decrese in data sent. Even though the gain is not the same as for the first $1000$ shuffles there seems to be some data transfer gain.

\bigskip

\begin{figure}
    \centering

    \begin{subfigure}{\textwidth}
        \centering
        \scalebox{.7}{
        \includegraphics[width=\textwidth]{figurs/const_ms_log_xy.eps}
        }
        \caption{}
        \label{fig:const_ms_plot}
    \end{subfigure}

    \vspace*{0cm}

    \begin{subfigure}{\textwidth}
        \centering
        \scalebox{.7}{
        \includegraphics[width=\textwidth]{figurs/eval_ms_log_xy.eps}
        }
        \caption{}
        \label{fig:eval_ms_plot}
    \end{subfigure}

    \vspace*{0cm}

    \begin{subfigure}{\textwidth}
        \centering
        \scalebox{.7}{
        \includegraphics[width=\textwidth]{figurs/total_ms_log_xy.eps}
        }
        \caption{}
        \label{fig:total_ms_plot}
    \end{subfigure}

    \caption{Time: Comparison of $Constructor$ and $Evaluator$ in $ms$'s used. (a) $Constructor$: Accumulated time per deck shuffled on a duble logarithmic scale. (b) $Evaluator$: Accumulated time per deck shuffled on a duble logaritmic scale. (c) $Total$: Accumulated time per deck shuffled on a duble logaritmic scale.}
    \label{fig:mesurement_ms}
\end{figure}

In the next section we will look a the time used per shuffled deck, which can be seen in figure \ref{fig:mesurement_ms}. The plots are the accumulated runningtimes per shuffled deck on a duble logarithmic scale. In figure \ref{fig:const_ms_plot} we see the time used in the different phases for the $Constructor$, in \ref{fig:eval_ms_plot} the $Evaluator$ and lastly in \ref{fig:total_ms_plot} we see the total time used on the framework calls. In figure \ref{fig:const_ms_plot} on the $Constructor$ side we see that the $Preprocess$ phase accumulates the most of the time. We also see that the time use in the $Preprocess$ phase is decreasing an approching $100$ ms per deck shuffled when shuffeling $3000$ decks simuntainiously. We also see that the $Evaluate$ phase does not add any significant time consumption to the evaluation. Where it is a completly different case when looking at the $Online$ phase. Here we see that the space between graphs encreases significantly when approching the $3000$ shuffled deck. We will take a look at this later. But for now we can conclude from the perspective of the $Constructor$ and in terms of accumulated running time per shuffled deck an optimum on this hardware is around $1500$ siminutanious shuffels. 
When looking at the $Evaluator$ in figure \ref{fig:eval_ms_plot} we see the same tendency as for the $Constructor$. The $Preprocess$ is the one using the most time and approching $150$ ms per shuffled deack. For the $Evaluator$ we see a small encreas in time used per shuffled deck when pasing the $1000$ mark. But over all the time spent on these two phases is still slightly decreasing. Once again we see a increase in the time used on the $Online$ phase. For the $Evaluator$ the encrease is more significant than for the $Constructor$. Therefore the optimal amount of shuffled deck from the $Evaluator$'s point of view is around $500$ decks.
When combining the running times from the $Constructor$ and $Evaluatro$ we get what we see in figure \ref{fig:total_ms_plot}. We see the same tendencies but with a optimum around $1500$.

This was not what was expected before doing the experiments. The expected outcome was that we would se a decrease in time used per shuffle. It was not expected that an encrease in time consumed would encrease when doing more than $2000$ shuffles. Therefore more experiments was done to cover the reasons.

\bigskip

\begin{figure}
    \centering

    \begin{subfigure}{\textwidth}
        \centering
        \scalebox{.7}{
        \includegraphics[width=\textwidth]{figurs/const_online_ms_log_xy.eps}
        }
        \caption{}
        \label{fig:const_online_ms_plot}
    \end{subfigure}

    \vspace*{0cm}

    \begin{subfigure}{\textwidth}
        \centering
        \scalebox{.7}{
        \includegraphics[width=\textwidth]{figurs/eval_online_ms_log_xy.eps}
        }
        \caption{}
        \label{fig:eval_online_ms_plot}
    \end{subfigure}

    \vspace*{0cm}

    \begin{subfigure}{\textwidth}
        \centering
        \scalebox{.7}{
        \includegraphics[width=\textwidth]{figurs/total_online_ms_log_xy.eps}
        }
        \caption{}
        \label{fig:total_online_ms_plot}
    \end{subfigure}

    \caption{$Online$ Time: Comparison of $Constructor$ and $Evaluator$ in $ms$'s used in the $Online$ phase. (a) $Constructor$: Accumulated time per deck shuffled on a duble logarithmic scale. (b) $Evaluator$: Accumulated time per deck shuffled on a duble logaritmic scale. (c) $Total$: Accumulated time per deck shuffled on a duble logaritmic scale.}
    \label{fig:mesurement_online_ms}
\end{figure}

In this part I will cover the reasons why we see a encrease in time consumed by the $Online$ phase. First off all we remember that the $Online$ phase has three \verb|DecodeKeys| calls. In figure \ref{fig:mesurement_online_ms} we see the accumulated times used on the \verb|DecodeKeys| framework calls. For the $Constructor$ in figure \ref{fig:const_online_ms_plot} we see a encreas in the time used on the first \verb|DecodeKeys| call. While the other calls decreases as expected. This implies that somthing happens in the first \verb|DecodeKeys| call that we did not expect. 
Looking at the $Evaluator$ in figure \ref{fig:eval_online_ms_plot} we see a graph that looks different, this is because the main work done in the \verb|DecodeKeys| call is done by the $Evaluator$. Here we see a increase in bothe the first and second \verb|DecodeKeys| call, while the third seems constant. 
When consulting the figure \ref{fig:total_online_ms_plot} for the combination of $Constructor$ and $Evaluator$ we see that the encrease in time used by the first \verb|DecodeKeys| call happend before $100$ shuffles, while the encrese by the second call happens after $500$ shuffles. 

\bigskip

The encrease in time spent on the \verb|DecodeKeys| calls is probably from the fact that the implementation tries to cach as much as possible. From figure \ref{fig:mesurement_kb} we see that in the $Online$ phase nearly no data is sent. By consulting the data appendix \ref{app:test-res} we see that approximatly $2.5$kb is sent. Sending this data on a network with a bandwith of $1$Gb/s takes $2.5$ms, which is negligable as the amount of data decreses. As explained earlier the test was done on a network with $50$ms latency. Since we do not know how many rounds of communication the two parties has, we can not conclude any thing from this, beside the fact that this can be seen as a constant. Therefor it must be some implementation specific detail of the framework which is different at the two parties. The fact that the $Constructo$ does not use any time in the second and third \verb|DecodeKeys| call indicate that some form of caching is taking place. 

\todo{Discuss the online phase.}
\todo{Main idea is IO wait.}
\todo{Timings in online phase is fluctuating, maybe I/O wait. More shuffles higher propability that some will end up waiting.}
\todo{Test ram only variant to see the rise in ms in online pahse is do to disk read, evt on 1000 shuffles}


\bigskip

\begin{figure}
    \centering

    \begin{subfigure}{\textwidth}
        \centering
        \scalebox{.7}{
        \includegraphics[width=\textwidth]{figurs/const_delay_log_xy.eps}
        }
        \caption{}
        \label{fig:const_delay_plot}
    \end{subfigure}

    \vspace*{0cm}

    \begin{subfigure}{\textwidth}
        \centering
        \scalebox{.7}{
        \includegraphics[width=\textwidth]{figurs/eval_delay_log_xy.eps}
        }
        \caption{}
        \label{fig:eval_delay_plot}
    \end{subfigure}

    \vspace*{0cm}

    \begin{subfigure}{\textwidth}
        \centering
        \scalebox{.7}{
        \includegraphics[width=\textwidth]{figurs/total_delay_log_xy.eps}
        }
        \caption{}
        \label{fig:total_delay_plot}
    \end{subfigure}
    \caption{Delay: Comparison of $Constructor$ and $Evaluator$ in $ms$'s used when $1000$ shuffles are done with different latency on the network. (a) $Constructor$: Accumulated time per deck shuffled on a duble logarithmic scale. (b) $Evaluator$: Accumulated time per deck shuffled on a duble logaritmic scale. (c) $Total$: Accumulated time per deck shuffled on a duble logaritmic scale.}
    \label{fig:mesurement_delay}
\end{figure}

\todo{different amount of delay}
In this section I will describe how the protocol handles network latency. This can be seen in figure \ref{fig:mesurement_delay}. In figure \ref{fig:total_delay_plot} that the overall impression is that the protocol handles delay fine until $100$ms. From here on it seems that there are a increase in the slowdown of the protocol. When looking at the $Constructor$ in figure \ref{fig:const_delay_plot} we see that the $Online$ phase is the one effected the most by the network latency. When comparing these graphs with table \ref{table:ping} it seems the protocol is performing fine for the latencies found there.

\bigskip

\begin{figure}
    \centering

    \begin{subfigure}{\textwidth}
        \centering
        \scalebox{.7}{
        \includegraphics[width=\textwidth]{figurs/const_bandwith_log_xy.eps}
        }
        \caption{}
        \label{fig:const_bandwith_plot}
    \end{subfigure}

    \vspace*{0cm}

    \begin{subfigure}{\textwidth}
        \centering
        \scalebox{.7}{
        \includegraphics[width=\textwidth]{figurs/eval_bandwith_log_xy.eps}
        }
        \caption{}
        \label{fig:eval_bandwith_plot}
    \end{subfigure}

    \vspace*{0cm}

    \begin{subfigure}{\textwidth}
        \centering
        \scalebox{.7}{
        \includegraphics[width=\textwidth]{figurs/total_bandwith_log_xy.eps}
        }
        \caption{}
        \label{fig:total_bandwith_plot}
    \end{subfigure}
    \caption{Bandwith: Comparison of $Constructor$ and $Evaluator$ in $ms$'s used when $1000$ shuffles are done with different bandwith on the network. (a) $Constructor$: Accumulated time per deck shuffled on a duble logarithmic scale. (b) $Evaluator$: Accumulated time per deck shuffled on a duble logaritmic scale. (c) $Total$: Accumulated time per deck shuffled on a duble logaritmic scale.}
    \label{fig:mesurement_bandwith}
\end{figure}

\todo{different amount of bandwidth}

\section{Discussion}
\label{sec:discussion}

\todo{ahead of time generation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conclution}
\label{ch:conclution}

\todo{future work}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{appendices}
\chapter{Codebase}
In this appendix references will presented to the different codebase used during the thesis. An url to the repositories on github will be presented togheter with a short description of where the most interresting parts for this project can be found.

\section{Hardware}
\label{app:hardware}
For compilations of the circuits with the $Frigate$ compiler the following setup has been used:

\begin{center}
\begin{verbatim}
OS:        Ubuntu 16.10/17.04
Processor: Intel i5-4210U CPU @ 1.70GHz
Cores:     2
Threads:   4
RAM:       12 GB
\end{verbatim}
\end{center}

I did not encounter any problems or slow compilations of circuits using this setup.

\bigskip
For the testing of the poker game that setup was not sufficient as it could not handle more than 500 simuntainios shuffles. Therefore another setup up was used:

\begin{center}
\begin{verbatim}
OS:        Ubuntu 16.04 LTS
Processor: Intel i7-3770K CPU @ 3.50GHz
Cores:     4
Threads:   8
RAMS:      32 GB
\end{verbatim}
\end{center}

This setup allowed for testing up to 3000 simuntainious shuffles, which is the highest done in the testing phase. When going up to 4000 this setup ran out of memmory on the $Evaluator$ site of the execution.


\section{DUPLO}
\label{app:duplo}
The \DUPLO repository at GitHub can be found here \footnote{\url{https://github.com/AarhusCrypto/DUPLO}}.

The documentation on the site is clear and illustrates clearly how it is compiled such it can be tested. No documentation is presented for how interacting with the framework can be done for new implementations. The most interesting part for the sake of this project is located in the \verb|src| folder. Here the \verb|CMakeLists.txt| file is located which specifies how the project is compiled, this is overwritten when compiling the poker implementation. The folder \verb|src/dublo-mains| is where the actual implementations of the $Constructor$ and $Evaluater$ can be found. Here the implementations of the poker $Constructor$ and $Evaluator$ will be placed.

\bigskip

For a easy setup of duplo a docker instance is created and can be found here \footnote{\url{https://hub.docker.com/r/cbobach/duplo/}}. This can be started in docker version \verb|17.05.0-ce| with the command;

\begin{center}
\begin{verbatim}
docker run -it --network:host cbobach/duplo
\end{verbatim}
\end{center}

The \verb|--network:host| flag is not secure but is the fart easy way to let the container running the $Constructor$ expose the port on wich the container running the $Evaluator$ needs to connect. When running two instances of these docker containers the $Constructor$ and $Evaluator$ is runned using one for these commands for the default setting:

\begin{center}
\begin{verbatim}
./build/release/DuploConstructor 
./build/release/DuploEvaluator
\end{verbatim}
\end{center}


\section{Frigate}
\label{app:frigate}
The $Frigate$ repository on GitHub is a subrepository to \DUPLO and can be found here \footnote{\url{https://github.com/AarhusCrypto/DUPLO/tree/master/frigate}}.

The documentation of how $Frigate$ is installed with the special versions of some of the libraries used is specified in the documentation of \DUPLO, the link can be found in appendix \ref{app:duplo}. It is also here the documentation of how to compile \DUPLO circuit formats are done.

To find the documentation of the \verb|.wir| file format a look should be taken at the link above. Here the specifications are of how wire acces is done for example. It is here all functionallities that are implemented in the language is listed and how they are used. This documentation is narrow at some places. It does for example not specify that the modulo operator \verb|%| does only work on powers of $2$.

\bigskip

Using the docker image from docker \footnote{\url{https://hub.docker.com/r/cbobach/duplo/}} and running the following command, in docker version \verb|17.05.0-ce|;

\begin{center}
\begin{verbatim}
docker run -it -v host/dir:container/dir cbobach/duplo
\end{verbatim}
\end{center}

will start a container where it is possible to compiler a \verb|.wir| file using the comtainer. For it to work the \verb|.wir| files has to be located in the \verb|host/dir| then the following commad can be run to compile the functionality:

\begin{center}
\begin{verbatim}
./build/release/Frigate container/dir/functionality.wir -dp
\end{verbatim}
\end{center}

The \verb|-db| flag ensures that the \DUPLO file format is generated. The \DUPLO generate file will have the extention \verb|.wir.GC_duplo| this can then be feeded to the \DUPLO framework using

\begin{center}
\begin{verbatim}
./build/release/DuploConstructor -f container/dir/functionality.wir.GC_duplo
./build/release/DuploEvaluator -f container/dir/functionality.wir.GC_duplo
\end{verbatim}
\end{center}

Then the new functionallity will be runned in the default \DUPLO environment.

\section{Poker}
\label{app:poker}
In this section the GitHub reposioties to the different pahses will be linked. A short description to where the intersting pars are will be presented.

\subsection{Circuit implemetation}
\label{app:circuit-impl}
The different circuit \verb|.wir| files can be foun in the Github repository here \footnote{\url{https://github.com/cbobach/speciale_circuit}}.

Here the implementations of the shuffle algorithms are present as \verb|fisher_yates_shuffle.wir| and \verb|conditional_swap_shuffle*.wir|. Multiple versions of the \verb|conditiona_swap_shuffle*.wir| file are present with different values for \verb|*|. This is to allow for multiple sequential hands to be plyead, these files are then used when testing the \DUPLO framework to show its capabilities.

Only one version of \verb|fisher_yates_shuffle.wir| is located in the repository since this is a slover algorithm in this setting as discussed in section \ref{sec:comp}.

The files \verb|init_deck.wir|, \verb|xor_seed.wir| and \verb|correcred_seed.wir| are all modules that are called by the shuffle algorithms. The \verb|init_deck.wir| file is used by both algorithms and hardwires the card values to their respective wires. The \verb|corrected_seed.wir| file is used by the \FY algorithm to ensure thet the seed feeded to the shuffle algorithm is in the correct intervalls as explained in section \ref{sec:fisher-yates}. The \verb|xor_seed.wir| file is used by the \CS algorithm ot generate the seed used by the shuffle.

\bigskip

It is also here that the parser used to debug the $Frigate$ compiler is located and is found as \verb|parse.py|. The other python script found in \verb|count-gate-types.py| is the one used to compare the amount of gates types for the compiled circuits.


\subsection{DUPLO implemetation}
\label{app:duplo-impl}
The poker repository for the implementation using the duplo framework can be found here \footnote{\url{https://github.com/cbobach/speciale_implementation}}.

Here the \verb|CMakeLists.txt| file is the one used to overwrite the original file found in the \DUPLO framework to allow for compilation of the poker $Constructor$ and $Evaluator$. In the folder \verb|duplo-mains| the implementations of these are located as \verb|poker-const-main.cpp| for the $Constructor$ and \verb|poker-eval-main.cpp| for the $Evaluator$. In this filder thir shared functionality is found in the \verb|poker-mains.h|.

\bigskip

Back in the main dir of the repository the docker files are found for generating the docker instanc of \DUPLO used in appendix \ref{app:duplo} and \ref{app:frigate}. This is the \verb|Dockerfile.DUPLO| where as the \verb|Dockerfile| is the one used for running the poker implementation. The \verb|entry-point.sh| files is used to start the docker containers correct shuch that thay can run in the background. The docker image can be found here \footnote{\url{https://hub.docker.com/r/cbobach/duplo-poker/}}. The containers can be started using the following commands in docker:

\begin{center}
\begin{verbatim}
docker run -d -p 2800:2800 cbobach/duplo-poker --profile const -i 0
docker run -d -network:host cbobach/duplo-poker --profile eval -i 0
\end{verbatim}
\end{center}

The \verb|-d| flag tells docker that the continers should run detached. The \verb|-p| flags tells docker to connect the host port $2800$ to the containers internal port 2800. \verb|--network:host| is the easy way to let the container have acces to the hosts network ports. These commands will play one hand of poker in the background, if more are required the \verb|-f| flag can be used to specify which circuits should be used. To get the the right timings the \verb|-n| falg is required together with the \verb|-f| flag. This flag needs to reflect the nomber of simuntainus shuffles in the circuit.

Using the \verb|-it| flag in docker instead of the \verb|-d| flag allow for interactive rounds of poker if the \verb|-i| flag is set to $1$ instead of $0$.


\subsection{Test results}
\label{app:test-res}
In this section a link to the repository on GitHub with all the generated statistics. Here all generated graphs and timings can be found. The repositor can be found here \footnote{\url{https://github.com/cbobach/speciale_thesis/tree/master/figurs}}

\bigskip

In the tables here the actual data used to generate the figure \ref{fig:mesurement_kb} and \ref{fig:mesurement_ms} in section \ref{sec:bechmarking} can be found.

\begin{table}
\centering

    \begin{subtable}{\textwidth}
    \label{table:const_kb}
    \centering
    \scalebox{1}{
    \begin{tabular}{l || r r r r r}
               & \multicolumn{5}{c}{Number of Parallel Shuffles} \\
    Phase      &         1 &       10 &     100 &    1000 & 3000 \\
    \hline
    Preprocess & 172140.31 & 26817.94 & 9380.99 & 7380.56 & 6219.38  \\
    Evaluate   &    122.84 &   122.84 &  122.84 &  122.84 &  122.84  \\
    Online     &      5.94 &     2.38 &    2.02 &    1.99 &    1.99  \\
    \hline
    Total      & 172269.09 & 26943.16 & 9505.85 & 7505.42 & 6344.21
    \end{tabular}
    }
    \caption{$Constructor$}
    \end{subtable}%
    
    \vspace*{.5cm}
    
    \begin{subtable}{\textwidth}
    \label{table:eval_kb}
    \centering
    \scalebox{1}{
    \begin{tabular}{l || r r r r r}
               & \multicolumn{5}{c}{Number of Parallel Shuffles} \\
    Phase      &      1 &    10 &   100 &  1000 & 3000 \\
    \hline
    Preprocess & 193.75 & 36.59 & 19.15 & 17.57 & 17.50 \\
    Evaluate   &   0.11 &  0.10 &  0.10 &  0.10 &  0.10 \\
    Online     &   1.44 &  0.58 &  0.49 &  0.48 &  0.48 \\
    \hline
    Total      & 195.30 & 37.27 & 19.74 & 18.15 & 18.08
    \end{tabular}
    }
    \caption{$Evaluator$}
    \end{subtable}%

    \vspace*{.5cm}
    
    \begin{subtable}{\textwidth}
    \label{table:eval_kb}
    \centering
    \scalebox{1}{
    \begin{tabular}{l || r r r r r}
               & \multicolumn{5}{c}{Number of Parallel Shuffles} \\
    Phase      &         1 &       10 &     100 &    1000 & 3000 \\
    \hline
    Preprocess & 172334.06 & 26854.53 & 9400.14 & 7398.13 & 6236.88 \\
    Evaluate   &    122.95 &   122.94 &  122.94 &  122.94 &  122.94 \\
    Online     &      7.38 &     2.96 &    2.51 &    2.47 &    2.47 \\
    \hline
    Total      & 172464.39 & 26980.43 & 9525.59 & 7523.57 & 6362.29 
    \end{tabular}
    }
    \caption{$Total$}
    \end{subtable}%

    \caption{Data sent: Comparison of $Constructor$ and $Evaluator$ in $kb$'s sent to the other party. (a) $Constructor$: $kb$'s data sent in different phases. (b) $Evaluator$: $kb$'s data sent in different phases.}
    \label{table:mesurmet_kb}
\end{table}

\begin{table}
    \centering

    \begin{subtable}{\textwidth}
    \centering
    \scalebox{1}{
    \begin{tabular}{l ||r r r r r}
          & \multicolumn{5}{c}{Number of Parallel Shuffles} \\
    Phase      &       1 &      10 &    100 &   1000 & 3000    \\
    \hline
    Preprocess & 8202.12 &  918.74 & 193.32 & 116.73 & 106.89 \\
    Evaluate   &  100.82 &   10.22 &   1.18 &   0.30 &   0.30 \\
    Online     &  301.09 &  120.84 & 103.38 & 116.60 & 179.35 \\
    \hline
    Total      & 8604.03 & 1049.80 & 297.88 & 233.63 & 286.54 
    \end{tabular}
    }
    \caption{$Constructor$}
    \label{table:const_ms}
    \end{subtable}%

    \vspace*{.5cm}

    \begin{subtable}{\textwidth}
    \centering
    \scalebox{1}{
    \begin{tabular}{l || r r r r r}
          & \multicolumn{5}{c}{Number of Parallel Shuffles} \\
    Phase      &       1 &     10 &    100 &   1000 & 3000    \\
    \hline
    Preprocess & 6619.65 & 823.37 & 187.27 & 119.74 & 118.28\\    
    Evaluate   &  129.49 &  17.91 &   5.43 &   5.44 &   9.58 \\
    Online     &  301.76 & 121.09 & 116.34 & 159.80 & 430.11\\
    \hline
    Total      & 7050.90 & 962.37 & 309.04 & 284.98 & 557.97
    \end{tabular}
    }
    \caption{$Evaluator$}
    \label{table:eval_ms}
    \end{subtable}%

    \vspace*{.5cm}

    \begin{subtable}{\textwidth}
    \centering
    \scalebox{1}{
    \begin{tabular}{l || r r r r r}
          & \multicolumn{5}{c}{Number of Parallel Shuffles} \\
    Phase      &        1 &      10 &    100 &   1000 & 3000    \\
    \hline
    Preprocess & 14821.77 & 1742.11 & 380.59 & 236.47 & 225.17 \\    
    Evaluate   &   230.31 &   28.13 &   6.61 &   5.74 &   9.88 \\
    Online     &   602.85 &  241.93 & 219.72 & 276.40 & 609.46 \\
    \hline
    Total      & 15654.93 & 2012.17 & 606.92 & 518.61 & 844.51 
    \end{tabular}
    }
    \caption{Total}
    \label{table:eval_ms}
    \end{subtable}%

    \caption{Comparison of $Constructor$ and $Evaluator$ in terms of time consumption in $ms$ during framework calls. (a) $Constructor$: Time consumption in different phases. (b) $Evalauator$: Time consumption in different phases. (c) $Total$: Time consumption in different phases.}
    \label{table:mesurement_ms}
\end{table}


\todo{Add log files to GitHub}

\todo{describe test bash script}



\end{appendices}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{references}{}
\bibliographystyle{plain} 

\end{document}